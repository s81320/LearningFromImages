{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model selection\n",
    "\n",
    "My initial model was pretty random, somehow based on the homework for fashion MNIST.\n",
    "\n",
    "I changed the 10 output classes to 2 and the b/w 1 channel input to 3 channels. The size of the images also had to be adjusted.\n",
    "\n",
    "When I work with the face images I expect that a high resolution is necessary. We should need more detail than what is needed to distinguish b/w a jeans and a boot. I have images 256 x 256 which is more than enough for the human eye. I will work with 128x128 image size. 64x64 still looks ok to me personally, but I don't want to start out throwing information away too much ...\n",
    "* \n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/LFI/bainbridge_2k/code\n",
      "2222\n",
      "requirements.txt\n",
      "*********\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (1.18.5)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (1.0.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (1.18.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.15.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (3.2.2)\n",
      "Requirement already satisfied: numpy>=1.11 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (1.18.5)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (1.4.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (0.5.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.18.5)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.15.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.4.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "main_dir = '/home/jovyan/LFI/bainbridge_2k/'\n",
    "\n",
    "# location of original labels: LFI/bainbridge_2k/meta\n",
    "label_file = '../meta/labels2k.xlsx'\n",
    "\n",
    "images_dir = '../images/'\n",
    "!ls $images_dir | wc -l #location for images , should output the number 2222\n",
    "!echo '*********'\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install torch\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-model-summary\n",
      "  Using cached pytorch_model_summary-0.1.2-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from pytorch-model-summary) (4.46.1)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from pytorch-model-summary) (1.4.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pytorch-model-summary) (1.18.5)\n",
      "Installing collected packages: pytorch-model-summary\n",
      "Successfully installed pytorch-model-summary-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-model-summary\n",
    "import pytorch_model_summary as pms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "#import cv2 # would like to remove this\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNeuralNetwork1(nn.Module):\n",
    "    '''original model taken from homework, for fashion MNIST.\n",
    "    Number of classes reduced from 10 to 2, \n",
    "    number of channels increased from 1 (b/w) to 3 (colour images).'''\n",
    "    def __init__(self):\n",
    "        super(MyNeuralNetwork1, self).__init__() \n",
    "        # TODO: YOUR CODE HERE\n",
    "        # no padding yet\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, stride=1, padding=1) # img.size 128*128=16'384 , 32 f-maps of size 124*124=15'376\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, stride=1, padding=1) # input feature.size 128*128\n",
    "        self.pool1 = nn.MaxPool2d(3, stride=2) # input feature.size halved to 64*64\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, stride=1, padding=1) # 62*62\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, stride=1, padding=1) # 60*60\n",
    "        self.pool2 = nn.MaxPool2d(3, stride=2) # features halved to size 30*30 \n",
    "        self.dropout2 = nn.Dropout2d(0.25)\n",
    "\n",
    "        # 64*29*29 = 53'824 , 61'504=64*961=64*31*31\n",
    "        self.fc1 = nn.Linear(61504, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: YOUR CODE HERE\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        #flatten\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        #x = F.relu(x) # removed this. with this i got outputs as mainly 0 - because most x before relu were negative.\n",
    "        # cf https://discuss.pytorch.org/t/always-output-of-0/21784/3\n",
    "        # suggesting to use no non-linearity before nn.CrossEntropyLoss.\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "      Layer (type)           Input Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "          Conv2d-1      [1, 3, 128, 128]             896             896\n",
      "          Conv2d-2     [1, 32, 128, 128]           9,248           9,248\n",
      "       MaxPool2d-3     [1, 32, 128, 128]               0               0\n",
      "       Dropout2d-4       [1, 32, 63, 63]               0               0\n",
      "          Conv2d-5       [1, 32, 63, 63]          18,496          18,496\n",
      "          Conv2d-6       [1, 64, 63, 63]          36,928          36,928\n",
      "       MaxPool2d-7       [1, 64, 63, 63]               0               0\n",
      "       Dropout2d-8       [1, 64, 31, 31]               0               0\n",
      "          Linear-9            [1, 61504]      62,981,120      62,981,120\n",
      "         Linear-10             [1, 1024]           2,050           2,050\n",
      "=========================================================================\n",
      "Total params: 63,048,738\n",
      "Trainable params: 63,048,738\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# summary(Net(), torch.zeros((1, 1, 28, 28)), show_input=True)\n",
    "# https://pypi.org/project/pytorch-model-summary/\n",
    "print(pms.summary(MyNeuralNetwork1(), torch.zeros((1, 3, 128, 128)), show_input=True))\n",
    "#print(pms.summary(MyNeuralNetwork1(), torch.zeros((1, 3, 128, 128)), show_input=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNeuralNetwork2(nn.Module):\n",
    "    def __init__(self):\n",
    "        '''Only 2 conv layers with pooling and dropout\n",
    "        Huge 1st fc layer, then immidiately reduce to 2 nodes in 2nd fc layer.'''\n",
    "        super(MyNeuralNetwork2, self).__init__() \n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1) # img.size 64*64=4096 , 32 f-maps of size 60*60=3'600\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, stride=1, padding=1) #\n",
    "        self.pool1 = nn.MaxPool2d(3, stride=2) # input feature.size halved to 32*32\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "\n",
    "        # 64*29*29 = 53'824 , 61'504=64*961=64*31*31\n",
    "        # 32*31*31 = 30'752\n",
    "        self.fc1 = nn.Linear(30752, 2)\n",
    "        self.fc2 = nn.Linear(2, 2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: YOUR CODE HERE\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        #flatten\n",
    "        print('right before flatten : ' , [x.size(i) for i in range(4)])\n",
    "        print(x.size(0))\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        #x = F.relu(x) # removed this. with this i got outputs as mainly 0 - because most x before relu were negative.\n",
    "        # cf https://discuss.pytorch.org/t/always-output-of-0/21784/3\n",
    "        # suggesting to use no non-linearity before nn.CrossEntropyLoss.\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right before flatten :  [1, 32, 31, 31]\n",
      "1\n",
      "-----------------------------------------------------------------------\n",
      "      Layer (type)         Input Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "          Conv2d-1      [1, 3, 64, 64]             896             896\n",
      "          Conv2d-2     [1, 32, 64, 64]           9,248           9,248\n",
      "       MaxPool2d-3     [1, 32, 64, 64]               0               0\n",
      "       Dropout2d-4     [1, 32, 31, 31]               0               0\n",
      "          Linear-5          [1, 30752]          61,506          61,506\n",
      "          Linear-6              [1, 2]               6               6\n",
      "=======================================================================\n",
      "Total params: 71,656\n",
      "Trainable params: 71,656\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n",
      "right before flatten :  [1, 32, 31, 31]\n",
      "1\n",
      "-----------------------------------------------------------------------\n",
      "      Layer (type)        Output Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "          Conv2d-1     [1, 32, 64, 64]             896             896\n",
      "          Conv2d-2     [1, 32, 64, 64]           9,248           9,248\n",
      "       MaxPool2d-3     [1, 32, 31, 31]               0               0\n",
      "       Dropout2d-4     [1, 32, 31, 31]               0               0\n",
      "          Linear-5              [1, 2]          61,506          61,506\n",
      "          Linear-6              [1, 2]               6               6\n",
      "=======================================================================\n",
      "Total params: 71,656\n",
      "Trainable params: 71,656\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(pms.summary(MyNeuralNetwork2(), torch.zeros((1, 3, 64, 64)), show_input=True))\n",
    "print(pms.summary(MyNeuralNetwork2(), torch.zeros((1, 3, 64, 64)), show_input=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNeuralNetwork3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNeuralNetwork3, self).__init__() \n",
    "        \n",
    "        # reduced to 8 feature maps\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3, stride=1, padding=1) # img.size 64*64=4096 , 8 f-maps\n",
    "        self.pool1 = nn.MaxPool2d(3, stride=2) # input feature.size halved to 32*32\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "\n",
    "        # 64*29*29 = 53'824 , 61'504=64*961=64*31*31\n",
    "        # 32*31*31 = 30'752 for 32 feature, half of it for 16 features\n",
    "        self.fc1 = nn.Linear(3844, 2)\n",
    "        self.fc2 = nn.Linear(2, 2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print('initial input tensor size : ' , [x.size(i) for i in range(4)])\n",
    "        x = self.conv1(x)\n",
    "        #print('after conv :' , [x.size(i) for i in range(4)])\n",
    "        x = F.relu(x)\n",
    "        #x = self.conv2(x)\n",
    "        #x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        #print('after pooling : ' , [x.size(i) for i in range(4)])\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        #flatten\n",
    "        #print('right before flatten : ' , [x.size(i) for i in range(4)])\n",
    "        #print(x.size(0))\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        #x = F.relu(x) # removed this. with this i got outputs as mainly 0 - because most x before relu were negative.\n",
    "        # cf https://discuss.pytorch.org/t/always-output-of-0/21784/3\n",
    "        # suggesting to use no non-linearity before nn.CrossEntropyLoss.\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "      Layer (type)         Input Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "          Conv2d-1      [1, 3, 64, 64]             112             112\n",
      "       MaxPool2d-2      [1, 4, 64, 64]               0               0\n",
      "       Dropout2d-3      [1, 4, 31, 31]               0               0\n",
      "          Linear-4           [1, 3844]           7,690           7,690\n",
      "          Linear-5              [1, 2]               6               6\n",
      "=======================================================================\n",
      "Total params: 7,808\n",
      "Trainable params: 7,808\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "      Layer (type)        Output Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "          Conv2d-1      [1, 4, 64, 64]             112             112\n",
      "       MaxPool2d-2      [1, 4, 31, 31]               0               0\n",
      "       Dropout2d-3      [1, 4, 31, 31]               0               0\n",
      "          Linear-4              [1, 2]           7,690           7,690\n",
      "          Linear-5              [1, 2]               6               6\n",
      "=======================================================================\n",
      "Total params: 7,808\n",
      "Trainable params: 7,808\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(pms.summary(MyNeuralNetwork3(), torch.zeros((1, 3, 64, 64)), show_input=True))\n",
    "print(pms.summary(MyNeuralNetwork3(), torch.zeros((1, 3, 64, 64)), show_input=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNeuralNetwork4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNeuralNetwork4, self).__init__() \n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, stride=1, padding=1) # img.size 128*128=16'384 , 32 f-maps of size 124*124=15'376\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, stride=1, padding=1) # input feature.size 128*128\n",
    "        self.pool1 = nn.MaxPool2d(3, stride=2) # input feature.size halved to 64*64\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "\n",
    "        # no increase in output channels, stick to 32 , maybe already decrease them?\n",
    "        self.conv3 = nn.Conv2d(32, 32, 3, stride=1, padding=1) # 30*30\n",
    "        self.conv4 = nn.Conv2d(32, 32, 3, stride=1, padding=1) # 28*28\n",
    "        self.pool2 = nn.MaxPool2d(3, stride=2) # features halved to size 14*14 \n",
    "        self.dropout2 = nn.Dropout2d(0.25)\n",
    "\n",
    "        # 64*29*29 = 53'824 , 61'504=64*961=64*31*31\n",
    "        self.fc1 = nn.Linear(30752, 4)\n",
    "        self.fc2 = nn.Linear(4, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: YOUR CODE HERE\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        #flatten\n",
    "        print('right before flatten : ' , [x.size(i) for i in range(4)])\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        #x = F.relu(x) # removed this. with this i got outputs as mainly 0 - because most x before relu were negative.\n",
    "        # cf https://discuss.pytorch.org/t/always-output-of-0/21784/3\n",
    "        # suggesting to use no non-linearity before nn.CrossEntropyLoss.\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right before flatten :  [1, 32, 31, 31]\n",
      "-------------------------------------------------------------------------\n",
      "      Layer (type)           Input Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "          Conv2d-1      [1, 3, 128, 128]             896             896\n",
      "          Conv2d-2     [1, 32, 128, 128]           9,248           9,248\n",
      "       MaxPool2d-3     [1, 32, 128, 128]               0               0\n",
      "       Dropout2d-4       [1, 32, 63, 63]               0               0\n",
      "          Conv2d-5       [1, 32, 63, 63]           9,248           9,248\n",
      "          Conv2d-6       [1, 32, 63, 63]           9,248           9,248\n",
      "       MaxPool2d-7       [1, 32, 63, 63]               0               0\n",
      "       Dropout2d-8       [1, 32, 31, 31]               0               0\n",
      "          Linear-9            [1, 30752]         123,012         123,012\n",
      "         Linear-10                [1, 4]              10              10\n",
      "=========================================================================\n",
      "Total params: 151,662\n",
      "Trainable params: 151,662\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n",
      "right before flatten :  [1, 32, 31, 31]\n",
      "-------------------------------------------------------------------------\n",
      "      Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "          Conv2d-1     [1, 32, 128, 128]             896             896\n",
      "          Conv2d-2     [1, 32, 128, 128]           9,248           9,248\n",
      "       MaxPool2d-3       [1, 32, 63, 63]               0               0\n",
      "       Dropout2d-4       [1, 32, 63, 63]               0               0\n",
      "          Conv2d-5       [1, 32, 63, 63]           9,248           9,248\n",
      "          Conv2d-6       [1, 32, 63, 63]           9,248           9,248\n",
      "       MaxPool2d-7       [1, 32, 31, 31]               0               0\n",
      "       Dropout2d-8       [1, 32, 31, 31]               0               0\n",
      "          Linear-9                [1, 4]         123,012         123,012\n",
      "         Linear-10                [1, 2]              10              10\n",
      "=========================================================================\n",
      "Total params: 151,662\n",
      "Trainable params: 151,662\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(pms.summary(MyNeuralNetwork4(), torch.zeros((1, 3, 128, 128)), show_input=True))\n",
    "print(pms.summary(MyNeuralNetwork4(), torch.zeros((1, 3, 128, 128)), show_input=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNeuralNetwork5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNeuralNetwork5, self).__init__() \n",
    "        # TODO: YOUR CODE HERE\n",
    "        # no padding yet\n",
    "        self.conv1 = nn.Conv2d(3, 24, 3, stride=1, padding=1) # img.size 128*128=16'384 , 32 f-maps of size 124*124=15'376\n",
    "        self.conv2 = nn.Conv2d(24, 24, 3, stride=1, padding=1) # input feature.size 128*128\n",
    "        self.pool1 = nn.MaxPool2d(3, stride=2) # input feature.size halved to 64*64\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "\n",
    "        # no increase in output channels, stick to 32 , maybe already decrease them?\n",
    "        self.conv3 = nn.Conv2d(24, 24, 3, stride=1, padding=1) # 30*30\n",
    "        self.conv4 = nn.Conv2d(24, 24, 3, stride=1, padding=1) # 28*28\n",
    "        self.pool2 = nn.MaxPool2d(3, stride=2) # features halved to size 14*14 \n",
    "        self.dropout2 = nn.Dropout2d(0.25)\n",
    "\n",
    "        # 64*29*29 = 53'824 , 61'504=64*961=64*31*31\n",
    "        self.fc1 = nn.Linear(23064, 4)\n",
    "        self.fc2 = nn.Linear(4, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: YOUR CODE HERE\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        #flatten\n",
    "        #print('right before flatten : ' , [x.size(i) for i in range(4)])\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        #x = F.relu(x) # removed this. with this i got outputs as mainly 0 - because most x before relu were negative.\n",
    "        # cf https://discuss.pytorch.org/t/always-output-of-0/21784/3\n",
    "        # suggesting to use no non-linearity before nn.CrossEntropyLoss.\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right before flatten :  [1, 24, 31, 31]\n",
      "-------------------------------------------------------------------------\n",
      "      Layer (type)           Input Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "          Conv2d-1      [1, 3, 128, 128]             672             672\n",
      "          Conv2d-2     [1, 24, 128, 128]           5,208           5,208\n",
      "       MaxPool2d-3     [1, 24, 128, 128]               0               0\n",
      "       Dropout2d-4       [1, 24, 63, 63]               0               0\n",
      "          Conv2d-5       [1, 24, 63, 63]           5,208           5,208\n",
      "          Conv2d-6       [1, 24, 63, 63]           5,208           5,208\n",
      "       MaxPool2d-7       [1, 24, 63, 63]               0               0\n",
      "       Dropout2d-8       [1, 24, 31, 31]               0               0\n",
      "          Linear-9            [1, 23064]          92,260          92,260\n",
      "         Linear-10                [1, 4]              10              10\n",
      "=========================================================================\n",
      "Total params: 108,566\n",
      "Trainable params: 108,566\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n",
      "right before flatten :  [1, 24, 31, 31]\n",
      "-------------------------------------------------------------------------\n",
      "      Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "          Conv2d-1     [1, 24, 128, 128]             672             672\n",
      "          Conv2d-2     [1, 24, 128, 128]           5,208           5,208\n",
      "       MaxPool2d-3       [1, 24, 63, 63]               0               0\n",
      "       Dropout2d-4       [1, 24, 63, 63]               0               0\n",
      "          Conv2d-5       [1, 24, 63, 63]           5,208           5,208\n",
      "          Conv2d-6       [1, 24, 63, 63]           5,208           5,208\n",
      "       MaxPool2d-7       [1, 24, 31, 31]               0               0\n",
      "       Dropout2d-8       [1, 24, 31, 31]               0               0\n",
      "          Linear-9                [1, 4]          92,260          92,260\n",
      "         Linear-10                [1, 2]              10              10\n",
      "=========================================================================\n",
      "Total params: 108,566\n",
      "Trainable params: 108,566\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(pms.summary(MyNeuralNetwork5(), torch.zeros((1, 3, 128, 128)), show_input=True))\n",
    "# print(pms.summary(MyNeuralNetwork5(), torch.zeros((1, 3, 128, 128)), show_input=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNeuralNetwork6(nn.Module):\n",
    "    def __init__(self):\n",
    "        '''3 blocks of convolution pooling, dropout.\n",
    "        Going down to 6x6 feature sizes.'''\n",
    "\n",
    "        super(MyNeuralNetwork6, self).__init__() \n",
    "        self.conv1 = nn.Conv2d(3, 24, 3, stride=1, padding=1) # img.size 128*128=16'384 , 24 f-maps of size 124*124=15'376\n",
    "        self.pool1 = nn.MaxPool2d(3, stride=2) # input feature.size halved to 62*62\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(24, 24, 3, stride=1, padding=1) # 30*30\n",
    "        self.pool2 = nn.MaxPool2d(3, stride=2) # features halved to size 15*15\n",
    "        self.dropout2 = nn.Dropout2d(0.25)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(24, 24, 3, stride=1, padding=1) # 13*13\n",
    "        self.pool3 = nn.MaxPool2d(3, stride=2) # features halved to size 6*6\n",
    "        self.dropout3 = nn.Dropout2d(0.25)\n",
    "\n",
    "        self.fc1 = nn.Linear(5400, 16)\n",
    "        self.fc2 = nn.Linear(16, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        #flatten\n",
    "        print('right before flatten : ' , [x.size(i) for i in range(4)])\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right before flatten :  [1, 24, 15, 15]\n",
      "-------------------------------------------------------------------------\n",
      "      Layer (type)           Input Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "          Conv2d-1      [1, 3, 128, 128]             672             672\n",
      "       MaxPool2d-2     [1, 24, 128, 128]               0               0\n",
      "       Dropout2d-3       [1, 24, 63, 63]               0               0\n",
      "          Conv2d-4       [1, 24, 63, 63]           5,208           5,208\n",
      "       MaxPool2d-5       [1, 24, 63, 63]               0               0\n",
      "       Dropout2d-6       [1, 24, 31, 31]               0               0\n",
      "          Conv2d-7       [1, 24, 31, 31]           5,208           5,208\n",
      "       MaxPool2d-8       [1, 24, 31, 31]               0               0\n",
      "       Dropout2d-9       [1, 24, 15, 15]               0               0\n",
      "         Linear-10             [1, 5400]          86,416          86,416\n",
      "         Linear-11               [1, 16]              34              34\n",
      "=========================================================================\n",
      "Total params: 97,538\n",
      "Trainable params: 97,538\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(pms.summary(MyNeuralNetwork6(), torch.zeros((1, 3, 128, 128)), show_input=True))\n",
    "# print(pms.summary(MyNeuralNetwork6(), torch.zeros((1, 3, 128, 128)), show_input=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I put those models in a .py file to import from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myModels import myModels as mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm1 = mm.MyNeuralNetwork1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "      Layer (type)           Input Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "          Conv2d-1      [1, 3, 128, 128]             896             896\n",
      "          Conv2d-2     [1, 32, 128, 128]           9,248           9,248\n",
      "       MaxPool2d-3     [1, 32, 128, 128]               0               0\n",
      "       Dropout2d-4       [1, 32, 63, 63]               0               0\n",
      "          Conv2d-5       [1, 32, 63, 63]          18,496          18,496\n",
      "          Conv2d-6       [1, 64, 63, 63]          36,928          36,928\n",
      "       MaxPool2d-7       [1, 64, 63, 63]               0               0\n",
      "       Dropout2d-8       [1, 64, 31, 31]               0               0\n",
      "          Linear-9            [1, 61504]      62,981,120      62,981,120\n",
      "         Linear-10             [1, 1024]           2,050           2,050\n",
      "=========================================================================\n",
      "Total params: 63,048,738\n",
      "Trainable params: 63,048,738\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(pms.summary(mm1, torch.zeros((1, 3, 128, 128)), show_input=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

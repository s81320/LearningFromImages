{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare saved models on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_available():  True\n"
     ]
    }
   ],
   "source": [
    "images_test_dir = '../images_test/'\n",
    "# to build PATH to save the best model\n",
    "model_dir = 'myModels/best/'\n",
    "# where to save plots from evaluation on the test set\n",
    "test_plots_dir = 'test_plots/'\n",
    "# eventually do evaluation for all models in model_dir\n",
    "# for now load a single model and get it to do predictions\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (\"torch.cuda.is_available(): \", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load one model\n",
    "run one of the cells. Each cell gets a PATH to a saved model in a *.pt-file and defines the model (the same modell class or type as the saved model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyNeuralNetwork3(\n",
       "  (conv1): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout1): Dropout2d(p=0.25, inplace=False)\n",
       "  (fc1): Linear(in_features=3844, out_features=2, bias=True)\n",
       "  (fc2): Linear(in_features=2, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from myModels import myModels as mm # mm = myModels\n",
    "\n",
    "PATH = model_dir+'MyNeuralNetwork3_acc9300.pt'\n",
    "model = mm.MyNeuralNetwork3()\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "model.eval() # we want to do predictions, not training\n",
    "model.to(device)\n",
    "# Make sure to call input = input.to(device) on any input tensors that you feed to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "PATH = model_dir+'resnet18_pretrained.pt'\n",
    "model = models.resnet18(pretrained=True)\n",
    "# adapt model as in training , repeat the transfer part\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "# now model fits the model we saved the parameters for\n",
    "\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "model.eval() # we want to do predictions, not training\n",
    "model.to(device)\n",
    "# Make sure to call input = input.to(device) on any input tensors that you feed to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images in images test dir ../images_test/ : \n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import test\n",
    "import pandas as pd\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "print('images in images test dir '+ images_test_dir +' : ' )\n",
    "!ls $images_test_dir | wc -l \n",
    "\n",
    "# imgH, imgW = model.get_img_shape()\n",
    "# for resNet\n",
    "imgH = imgW = 224\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((imgH,imgW)), # imgH, imgW as required for model\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "df = pd.read_csv('../meta/labels2k_A_test.csv', index_col=0) \n",
    "df.index=range(df.shape[0])\n",
    "setup = df[['Gender','Age','Race','newFilename']].copy()\n",
    "\n",
    "testset = test.TestSet(images_dir=images_test_dir , setup=setup, transform=transform)\n",
    "batch_size=5 # this should be automated # this can be set to any value! 1,5,10, 100 (=size of test set)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import numpy as np\n",
    "\n",
    "def run_test_short(data_loader, model):\n",
    "    \n",
    "    # running statistic ends with _r\n",
    "    error_eg_r = np.zeros((7,2))\n",
    "    tots_r = np.zeros((7,2))\n",
    "    \n",
    "    error_rel = np.zeros((3,2))\n",
    "\n",
    "    # do not compute gradients\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            \n",
    "            # batch statistic end with _b\n",
    "            error_eg_b = np.zeros((7,2))\n",
    "            tots_b = np.zeros((7,2))\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            preds = preds.tolist()\n",
    "        \n",
    "            labels_e = labels['ethnicity'].tolist()\n",
    "            labels_f = labels['file']\n",
    "            labels_g = labels['gender'].tolist()\n",
    "              \n",
    "            diff = [i-j for (i,j) in zip(labels_g,preds)] # values -1,0,1\n",
    "            for d , e , g  in zip(diff, labels_e, labels_g):\n",
    "                error_eg_b[e,g] += d*d # error : d==1,-1 then d*d = 1, so we add 1 to the error matrix at [e,g]\n",
    "                tots_b[e,g]+=1\n",
    "                \n",
    "            # running statistic, ends with _r\n",
    "            error_eg_r += error_eg_b\n",
    "            tots_r += tots_b\n",
    "\n",
    "    error_eg_r[3,:] += error_eg_r[0,:]+error_eg_r[4:7,:].sum(axis=0)\n",
    "    error_eg_r = error_eg_r[1:4]\n",
    "    \n",
    "    tots_r[3,:] += tots_r[0,:]+tots_r[4:7,:].sum(axis=0)\n",
    "    tots_r = tots_r[1:4]\n",
    "    \n",
    "    return error_eg_r , tots_r \n",
    "\n",
    "def matrix_division (error, tots):\n",
    "    '''given 2 matrices of same shape, divide one by the other, element wise'''\n",
    "    assert error.shape == tots.shape, 'matrices have to be of the same shape.'\n",
    "    \n",
    "    error_rel = np.zeros(error.shape)\n",
    "    \n",
    "    for e in range(error.shape[0]):\n",
    "        for g in range(error.shape[1]):\n",
    "            if tots[e,g]==0:\n",
    "                error_rel[e,g]=None\n",
    "            else:\n",
    "                error_rel[e,g] = error[e,g] / tots[e,g]\n",
    "    return error_rel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell does the work and produces the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TestSet.len returning : 100\n",
      "accuracy :  0.95\n",
      "highest error rate in ethnicities 1,2 : 0.16666666666666666\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "err, tot = run_test_short(test_loader, model)\n",
    "err_rel = matrix_division(err,tot)\n",
    "#print(err_rel)\n",
    "sns.heatmap(err_rel, linewidth=0.5, annot=True)\n",
    "plt.title('error rates for ethnicity gender combinations\\n'+PATH)\n",
    "plt.xlabel('gender')\n",
    "plt.ylabel('ethnicitiy')\n",
    "try:\n",
    "    plt.savefig(test_plots_dir+model.get_model_name()+'_error.png')\n",
    "except:\n",
    "    plt.savefig(test_plots_dir+'resnet_error.png')\n",
    "#plt.show()\n",
    "# put these numbers in an np array or pandas df\n",
    "print('accuracy : ' , (tot.sum() - err.sum()) / tot.sum() )\n",
    "print('highest error rate in ethnicities 1,2 :' , max(np.ravel(err_rel[0:2,:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this model MyNeuralNetwork3 the validation accuracy was .93, on the test set we gor .87\n",
    "So the model got lucky on the dev set but not on the test set. too bad ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_0():\n",
    "    # running statistics end with _r\n",
    "    cfm_r = np.zeros((2,2))\n",
    "    recall_by_e_r = np.zeros((2,7,2))\n",
    "    f1_r = [] \n",
    "\n",
    "    # do not compute gradients\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "        \n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            preds = preds.tolist()\n",
    "        \n",
    "            labels_e = labels['ethnicity'].tolist()\n",
    "            labels_f = labels['file']\n",
    "            labels_g = labels['gender'].tolist()\n",
    "            labels_a = labels['age'].tolist()\n",
    "        \n",
    "            # batch statistics, end with _b\n",
    "            cfm_b = confusion_matrix(labels_g, preds, labels=[0,1])\n",
    "\n",
    "            recall_by_e_b = np.zeros((2,7,2), dtype=np.int8)\n",
    "            diff = [i-j for (i,j) in zip(labels_g,preds)] # values -1,0,1\n",
    "            for d , e , g  in zip(diff, labels_e, labels_g):\n",
    "                recall_by_e_b[d, e, g] += 1 \n",
    "                \n",
    "            # running statistics, end with _r\n",
    "            cfm_r += cfm_b\n",
    "            recall_by_e_r += recall_by_e_b\n",
    "\n",
    "    tn, fp, fn, tp = cfm_r.ravel()\n",
    "    f1_m = 2*tp/(2*tp+fp+fn) # male as positive class\n",
    "    f1_f = 2*tn/(2*tn+fp+fn) # female as positive class (or f1 for the negaive class)\n",
    "\n",
    "    #print('confusion matrix : \\n' , cfm_r )\n",
    "    #print('f1 score for the male/1 class: ' , round(f1_m,4) , '\\nf1 for female/0 class : ' , round(f1_f,4) )\n",
    "    df2 = pd.DataFrame(np.concatenate([recall_by_e_r[0,:,:],recall_by_e_r[1,:,:]], axis=1))\n",
    "    print('gender recall grouped by ethnicity:\\n' , df2)\n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TestSet.len returning : 100\n",
      "gender recall grouped by ethnicity:\n",
      "       0     1    2    3\n",
      "0   0.0   0.0  0.0  0.0\n",
      "1  32.0  40.0  3.0  7.0\n",
      "2   3.0   6.0  1.0  0.0\n",
      "3   2.0   1.0  0.0  0.0\n",
      "4   0.0   0.0  0.0  0.0\n",
      "5   2.0   1.0  0.0  1.0\n",
      "6   0.0   0.0  0.0  1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[32., 40.,  3.,  7.],\n",
       "       [ 3.,  6.,  1.,  0.],\n",
       "       [ 4.,  2.,  0.,  2.]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = run_test_0()\n",
    "a = df2.loc[[1,2,3]].to_numpy() # take 3 rows for ethnicities 1=white, 2=black, 3,4=...asian , 5=latinxplt.imshow(a, cmap='hot', interpolation='nearest')\n",
    "a[2,:]= a[2,:]+df2.loc[[0,4,5,6]].sum(axis=0) # add the other rows to the asian row , row 0 was for undecided ethnicity and is empty in the test set\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall = tp/(tp+fn) for the positive class female (=0) or male (=1)\n",
    "# rows in a : [t*, t* , f* ,f*] correct classification (d=0) in the first 2 columns, misclassifications (d=1,-1) in the 3rd, 4th column\n",
    "# consider 0/female the positive class then the rows are [tp,tn,fn,fp] , because labeled females are gender 0 in columns 1 and 3 (0based column indexes: 0,2)\n",
    "# consider 1/male the positive class then the rows are [tn,tp,fp,fn]\n",
    "\n",
    "def tpr (b,g): # g in {0,1}, g+2 in {2,3}, so g,g+2 =0,2 or =1,3 the indices for recall in [t*,t*,f*,f*] depending on gender g\n",
    "    if b[g]+b[g+2]: # true when sum positive\n",
    "        return b[g]/(b[g]+b[g+2])\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def re_call (a):\n",
    "    b = np.zeros((3,2))\n",
    "    for e in range(3):\n",
    "        for g in range(2):\n",
    "            b[e,g]= tpr(a[e,:],g)\n",
    "    return b # np.round(100*b,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#import matplotlib.pylab as plt\n",
    "\n",
    "def heatmap_recall(b): \n",
    "    ax = sns.heatmap(b, linewidth=0.5, annot=True)\n",
    "    plt.title('recall of gender grouped by ethnicity')\n",
    "    plt.xlabel('each gender as positive class')\n",
    "    plt.ylabel('ethnicity')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
